#! /bin/bash
#SBATCH --job-name=charac
#SBATCH --nodes=1
#SBATCH --mem=50Gb
#SBATCH --output=slurm-logs/preproc.%j.out
#SBATCH --error=slurm-logs/preproc.%j.err


module load spark/2.3.2-hadoop2.7
module load python/2.7.15



source /scratch/armin_m/spark/conf/spark-env.sh



ulimit -u 10000


spark-submit --master local[20]   --py-files "helpers.py"  --executor-memory 100g --driver-memory 100g   Characteristics.py   $1  $2   $3  $4 --N $5    --undirected --fromSnap 



